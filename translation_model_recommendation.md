# 번역 모델 업그레이드 제안 보고서

## 1. 현재 상황 및 문제점 (Current Status & Problem)
*   **현재 모델:** `facebook/nllb-200-distilled-600M` (약 6억 파라미터)
*   **문제점:**
    *   모델 사이즈가 작아 한국어 번역 품질이 만족스럽지 않음 (오역, 문맥 파악 부족).
    *   `nllb-200-1.3B`나 `llama3`로도 큰 성능 향상을 체감하지 못함.

---

## 2. 해결을 위한 모델 옵션 (Options)

사용자께서 문의하신 **NVIDIA 모델**을 포함하여, 현재 **한국어 번역 성능이 우수하다고 평가받는** 대표적인 오픈소스 모델 3가지를 비교 분석했습니다.

### 옵션 A: NVIDIA Riva-Translate-4B-Instruct-v1.1 (추천 ⭐)
*   **제작사:** NVIDIA
*   **크기:** 4B (약 40억 파라미터)
*   **특징:**
    *   한국어를 포함한 12개 핵심 언어에 집중하여 학습됨.
    *   NVIDIA의 최신 NMT(신경망 기계 번역) 기술이 적용되어 성능 최적화.
    *   600M 모델보다 훨씬 강력하지만, 7B(Llama급) 모델보다는 가벼워 로컬 실행 부담이 덜함.
*   **장점:** 번역 전용으로 튜닝되어 안정적이며, 한국어 지원이 명시적으로 포함됨.
*   **단점:** 범용 LLM보다는 문맥 이해도가 낮을 수 있음 (하지만 번역 목적에는 적합).

### 옵션 B: google/madlad-400-3b-mt
*   **제작사:** Google
*   **크기:** 3B (약 30억 파라미터)
*   **특징:**
    *   T5 아키텍처 기반의 다국어 번역 모델.
    *   450개 이상의 언어를 지원하며, 리소스 대비 성능 효율이 좋음.
*   **장점:** NVIDIA 모델보다 가벼우면서도 구글의 방대한 데이터셋으로 학습되어 성능이 준수함.
*   **단점:** 한국어 특화(뉴앙스 처리 등) 면에서는 최신 Instruct 모델들에 비해 조금 기계적인 느낌을 줄 수 있음.

### 옵션 C: Unbabel/TowerInstruct-7B-v0.2
*   **제작사:** Unbabel
*   **크기:** 7B (약 70억 파라미터)
*   **특징:**
    *   Llama 2 기반으로 번역 작업에 특화(Fine-tuned)된 모델.
    *   GPT-3.5와 견줄만한 번역 성능을 보여준다는 벤치마크 결과가 있음.
*   **장점:** 문맥 이해도와 번역 자연스러움이 가장 뛰어남.
*   **단점:** **모델이 무거움.** (VRAM 16GB 이상 권장). 실행 속도가 느릴 수 있음.

---

## 3. 종합 비교 및 추천 (Recommendation)

| 모델명 | 파라미터 크기 | VRAM 요구사항 (추정) | 한국어 성능 | 속도 | 비고 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **NVIDIA Riva-Translate** | **4B** | **약 8~10GB** | **우수 (High)** | **빠름** | **균형 잡힌 선택** |
| MADLAD-400 | 3B | 약 6~8GB | 양호 (Good) | 매우 빠름 | 가성비 좋음 |
| TowerInstruct | 7B | 약 16GB+ | 최상 (Best) | 느림 | 고사양 GPU 필요 |

### 🚀 최종 제안: **옵션 A (NVIDIA Riva-Translate-4B)**

사용자께서 문의하신 **`nvidia/Riva-Translate-4B-Instruct-v1.1`** 은 현재 상황에서 **가장 합리적인 선택**입니다.
1.  **성능:** 기존 600M 모델 대비 확실한 품질 향상을 기대할 수 있습니다.
2.  **효율성:** 7B 모델보다 가벼워 실행 속도와 자원 소모 면에서 부담이 적습니다.
3.  **목적 적합성:** 번역 전용 모델(Machine Translation)로서 안정적인 결과를 제공합니다.

### 4. 적용 계획 (Plan)
승인해 주시면 다음과 같이 작업을 진행하겠습니다.

1.  **패키지 설치**: `pip install transformers` (이미 설치됨 확인)
2.  **FastAPI 코드 수정 (`@fastapi_ai_translation`)**:
    *   기존 `facebook/nllb...` 모델 로드 부분을 `nvidia/Riva-Translate-4B-Instruct-v1.1` 로 변경.
    *   프롬프트 포맷이 Instruct 방식일 경우, 입력 처리 로직을 해당 모델에 맞게 수정.
3.  **테스트**: 서버 재시작 후 번역 품질 테스트 진행.

동의하시면 **"진행해"** 라고 말씀해 주세요! 바로 적용하겠습니다.
