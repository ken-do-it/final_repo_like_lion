import logging
import os
import hashlib
import requests
import json
from fastapi import FastAPI, HTTPException
# from translation.router import router as translation_router  # AI ë²ˆì—­ ë¼ìš°í„° (Moved)
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
from database import get_db_connection
from prometheus_fastapi_instrumentator import Instrumentator

# ---------------------------------------------------------
# ë²ˆì—­ ê´€ë ¨ ì„¤ì •
# ---------------------------------------------------------
FASTAPI_TRANSLATE_URL = os.getenv("FASTAPI_TRANSLATE_URL", "http://fastapi-ai-translation:8003/api/ai/translate")
AI_SERVICE_API_KEY = os.getenv("AI_SERVICE_API_KEY", "secure-api-key-1234")

def parse_cached_translation(cached_text: str) -> str:
    """ìºì‹œëœ ë²ˆì—­ ë°ì´í„° íŒŒì‹± (JSON í˜•ì‹ì¸ ê²½ìš° ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ)"""
    if not cached_text:
        return cached_text

    # JSON í˜•ì‹ì¸ì§€ í™•ì¸
    if cached_text.strip().startswith('{'):
        try:
            data = json.loads(cached_text)
            # { "translations": ["..."] } í˜•ì‹
            if "translations" in data and isinstance(data["translations"], list):
                return data["translations"][0] if data["translations"] else cached_text
            # { "translated_text": "..." } í˜•ì‹
            if "translated_text" in data:
                return data["translated_text"]
        except (json.JSONDecodeError, IndexError, KeyError):
            pass

    return cached_text

def call_translate_api(text: str, source_lang: str, target_lang: str, timeout: int = 20):
    """FastAPI ë²ˆì—­ ì„œë²„ í˜¸ì¶œ"""
    if not text or not text.strip():
        return text

    payload = {
        "text": text,
        "source_lang": source_lang,
        "target_lang": target_lang,
    }

    try:
        headers = {"x-ai-api-key": AI_SERVICE_API_KEY}
        resp = requests.post(FASTAPI_TRANSLATE_URL, json=payload, headers=headers, timeout=(3, timeout))
        resp.raise_for_status()
        data = resp.json()

        # ì‘ë‹µ í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬
        result = None
        if "translated_text" in data:
            result = data["translated_text"]
        elif "translations" in data and isinstance(data["translations"], list):
            result = data["translations"][0] if data["translations"] else text

        # ì´ì¤‘ JSON ì²˜ë¦¬ (translated_textê°€ JSON ë¬¸ìì—´ì¸ ê²½ìš°)
        if result:
            result = parse_cached_translation(result)

        return result if result else text
    except Exception as e:
        logger.error(f"Translation API error: {e}")
        return text

def translate_items(items: List[Dict], target_lang: str, entity_type: str, fields: List[str], conn):
    """
    ê²€ìƒ‰ ê²°ê³¼ ì•„ì´í…œë“¤ì— ëŒ€í•´ ë²ˆì—­ ì²˜ë¦¬
    1. translation_entries í…Œì´ë¸”ì—ì„œ ìºì‹œ í™•ì¸
    2. ìºì‹œ ì—†ìœ¼ë©´ ë²ˆì—­ API í˜¸ì¶œ í›„ ìºì‹œ ì €ì¥
    """
    if not target_lang or not items:
        return

    cur = conn.cursor()

    for item in items:
        entity_id = item.get("id")
        if not entity_id:
            continue

        # ì›ë³¸ ì–¸ì–´ ì¶”ì • (ê¸°ë³¸ê°’: í•œêµ­ì–´)
        source_lang = item.get("source_lang", "kor_Hang")

        # ì›ë³¸ ì–¸ì–´ì™€ íƒ€ê²Ÿ ì–¸ì–´ê°€ ê°™ìœ¼ë©´ ìŠ¤í‚µ
        if source_lang == target_lang:
            for field in fields:
                item[f"{field}_translated"] = item.get(field, "")
            continue

        for field in fields:
            original_text = item.get(field, "")
            if not original_text:
                item[f"{field}_translated"] = ""
                continue

            # 1. ìºì‹œ í™•ì¸
            cur.execute("""
                SELECT translated_text FROM translation_entries
                WHERE entity_type = %s AND entity_id = %s AND field = %s AND target_lang = %s
                LIMIT 1
            """, (entity_type, entity_id, field, target_lang))

            cache_row = cur.fetchone()

            if cache_row:
                # ìºì‹œ Hit - JSON í˜•ì‹ì¸ ê²½ìš° íŒŒì‹±
                item[f"{field}_translated"] = parse_cached_translation(cache_row[0])
            else:
                # ìºì‹œ Miss -> ë²ˆì—­ API í˜¸ì¶œ
                translated = call_translate_api(original_text, source_lang, target_lang)
                item[f"{field}_translated"] = translated

                # ìºì‹œ ì €ì¥
                if translated and translated != original_text:
                    try:
                        text_hash = hashlib.sha256(original_text.encode("utf-8")).hexdigest()
                        cur.execute("""
                            INSERT INTO translation_entries
                            (entity_type, entity_id, field, source_lang, target_lang, source_hash, translated_text, provider, model, created_at, updated_at, last_used_at)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW(), NOW())
                            ON CONFLICT (entity_type, entity_id, field, target_lang) DO UPDATE
                            SET translated_text = EXCLUDED.translated_text, source_hash = EXCLUDED.source_hash, updated_at = NOW(), last_used_at = NOW()
                        """, (entity_type, entity_id, field, source_lang, target_lang, text_hash, translated, "fastapi", "nllb"))
                        conn.commit()
                    except Exception as e:
                        logger.error(f"Cache save error: {e}")
                        conn.rollback()

# ì‚­ì œ ìš”ì²­ ë°ì´í„° ëª¨ë¸
class DeleteRequest(BaseModel):
    id: int      # ì¥ê³ ì—ì„œ ë³´ë‚´ì¤€ ì›ë³¸ ID (Place ID)
    category: str


from dotenv import load_dotenv
load_dotenv()


# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
try:
    from sentence_transformers import SentenceTransformer
    import psycopg2
    from pgvector.psycopg2 import register_vector
except ImportError as e:
    print(f"CRITICAL ERROR: í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤! -> {e}")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(root_path="/search-api")
Instrumentator().instrument(app).expose(app)

# ---------------------------------------------------------
# CORS ì„¤ì • (ëª¨ë“  ë„ë©”ì¸ í—ˆìš© - ê°œë°œìš©)
# ---------------------------------------------------------
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì£¼ì†Œ í—ˆìš© (OPTIONS 400 ì—ëŸ¬ í•´ê²°)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ëª¨ë¸ ì „ì—­ ë³€ìˆ˜
model = None

# ---------------------------------------------------------
# â˜… DB ì„¤ì • 
# ---------------------------------------------------------
DB_HOST = os.getenv("DB_HOST", "db")
DB_NAME = os.getenv("DB_NAME", "korea_travel_db")
DB_USER = os.getenv("DB_USER", "myuser")
DB_PASS = os.getenv("DB_PASSWORD", "mypassword")

def init_db():
    """ì„œë²„ ì‹œì‘ ì‹œ í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # í…Œì´ë¸” ìƒì„± (IF NOT EXISTS)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS search_vectors (
                uid SERIAL PRIMARY KEY,
                target_id INT,
                category VARCHAR(50),
                content TEXT,
                embedding vector(384) 
            );
        """)
        # ì¸ë±ìŠ¤ ìƒì„± (ì†ë„ í–¥ìƒì„ ìœ„í•´ ê¶Œì¥ - ivfflat ë°©ì‹ ì˜ˆì‹œ)
        # ë°ì´í„°ê°€ ì ì„ ë• ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¼ë‹¨ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜, ë°ì´í„° ìŒ“ì¸ í›„ ìƒì„±
        # cur.execute("CREATE INDEX ON search_vectors USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);")
        
        conn.commit()
        cur.close()
        conn.close()
        logger.info("âœ… DB í…Œì´ë¸” ì´ˆê¸°í™” ì™„ë£Œ (search_vectors)")
    except Exception as e:
        logger.error(f"âŒ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

@app.on_event("startup")
async def startup_event():
    global model
    
    # 1. DB í…Œì´ë¸” ë¨¼ì € ìƒì„± (ìˆœì„œ ì¤‘ìš”)
    init_db()
    
    # 2. ëª¨ë¸ ë¡œë”©
    logger.info("ğŸš€ AI ëª¨ë¸ ë¡œë”© ì‹œì‘...")
    try:
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        logger.info("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")

def get_db_connection():
    try:
        conn = psycopg2.connect(host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASS)
        cur = conn.cursor()
        cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
        conn.commit()
        register_vector(conn)
        return conn
    except Exception as e:
        logger.error(f"DB ì—°ê²° ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=f"DB Connection Error: {str(e)}")




# ---------------------------------------------------------
# AI ë²ˆì—­ ë¼ìš°í„° ë“±ë¡ (Hugging Face Inference API)
# ---------------------------------------------------------
# ---------------------------------------------------------
# AI ë²ˆì—­ ë¼ìš°í„° ë“±ë¡ (Removed: Moved to fastapi_ai_translation)
# ---------------------------------------------------------
# app.include_router(translation_router, prefix="/api/ai", tags=["translation"])






# ---------------------------------------------------------
# 1. í†µí•© ë°ì´í„° ë“±ë¡ API (Index Data)
# ---------------------------------------------------------
class IndexRequest(BaseModel):
    id: int          # ì›ë³¸ ID (ì¥ì†ŒID, ì¹¼ëŸ¼ID, ë¦¬ë·°ID ë“±)
    category: str    # ë¶„ë¥˜ ('place', 'column', 'review', 'plan' ë“±)
    content: str     # ê²€ìƒ‰ë  í…ìŠ¤íŠ¸ ë‚´ìš©

@app.post("/index-data")
def index_data(request: IndexRequest):
    if model is None:
        raise HTTPException(status_code=500, detail="ëª¨ë¸ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤.")

    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # â˜… í…Œì´ë¸” êµ¬ì¡° ë³€ê²½: category ì»¬ëŸ¼ ì¶”ê°€!
        cur.execute("""
            CREATE TABLE IF NOT EXISTS search_vectors (
                uid SERIAL PRIMARY KEY,
                target_id INT,           -- ì›ë³¸ ë°ì´í„°ì˜ ID
                category VARCHAR(50),    -- ë°ì´í„° ì¢…ë¥˜ (place, review ë“±)
                content TEXT,
                embedding vector(384) 
            );
        """)
        
        # â˜… Unique Index ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€ìš©)
        cur.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_target_category ON search_vectors (target_id, category);")
        
        # í…ìŠ¤íŠ¸ -> ë²¡í„° ë³€í™˜
        embedding = model.encode(request.content).tolist()
        
        # ë°ì´í„° ì €ì¥ (UPSERT: ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…)
        query = """
            INSERT INTO search_vectors (target_id, category, content, embedding) 
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (target_id, category) 
            DO UPDATE SET content = EXCLUDED.content, embedding = EXCLUDED.embedding;
        """
        cur.execute(query, (request.id, request.category, request.content, embedding))
        conn.commit()
        conn.close()
        
        logger.info(f"ë°ì´í„° ë“±ë¡ ì„±ê³µ [{request.category}]: {request.content}")
        return {"status": "success", "message": f"Indexed ({request.category}): {request.content}"}
        
    except Exception as e:
        logger.error(f"ë“±ë¡ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ---------------------------------------------------------
# 2. í†µí•© ê²€ìƒ‰ API (ë¶„ë¥˜ëœ ê²°ê³¼ ë°˜í™˜)
# ---------------------------------------------------------
class SearchRequest(BaseModel):
    query: str
    lang: str = None  # íƒ€ê²Ÿ ì–¸ì–´ (ì˜ˆ: eng_Latn, kor_Hang, jpn_Jpan, zho_Hans)

# @app.post("/search")
# def search_grouped(request: SearchRequest):
#     logger.info(f"ğŸ” ë¶„ë¥˜ ê²€ìƒ‰ ìš”ì²­: {request.query}")

#     if model is None:
#         raise HTTPException(status_code=500, detail="ëª¨ë¸ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤.")

#     try:
#         conn = get_db_connection()
#         cur = conn.cursor()
        
#         # 1. ì¿¼ë¦¬ ë²¡í„° ë³€í™˜
#         query_vector = model.encode(request.query).tolist()
#         text_pattern = f"%{request.query}%"

#         # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ í¬í•¨ ì‹œ ìš°ì„ ìˆœìœ„)
#         # category ì»¬ëŸ¼ë„ ê°™ì´ ì¡°íšŒí•©ë‹ˆë‹¤.
#         cur.execute("""
#             SELECT target_id, category, content, (embedding <=> %s::vector) as distance,
#                    CASE WHEN content ILIKE %s THEN 0 ELSE 1 END as match_priority
#             FROM search_vectors
#             ORDER BY match_priority ASC, distance ASC
#             LIMIT 30;  -- ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ê°€ ì„ì—¬ ë‚˜ì˜¤ë¯€ë¡œ ë„‰ë„‰í•˜ê²Œ ì¡°íšŒ
#         """, (query_vector, text_pattern))
        
#         rows = cur.fetchall()
#         conn.close()
        
#         # 3. â˜… íŒŒì´ì¬ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë°•ìŠ¤ ë‹´ê¸° (Grouping)
#         grouped_results = {
#             "places": [],
#             "reviews": [],
#             "plans": [],
#             "others": []
#         }
        
#         for r in rows:
#             item = {
#                 "id": r[0],
#                 "content": r[2],
#                 "distance": float(r[3]),
#                 "is_keyword_match": True if r[4] == 0 else False
#             }
            
#             # ê¼¬ë¦¬í‘œ(category) í™•ì¸ í›„ ë¶„ë¥˜
#             cat = r[1] 
#             if cat == "place":
#                 grouped_results["places"].append(item)
#             elif cat == "review":
#                 grouped_results["reviews"].append(item)
#             elif cat == "plan":
#                 grouped_results["plans"].append(item)
#             else:
#                 grouped_results["others"].append(item)
        
#         return grouped_results
        
#     except Exception as e:
#         logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
#         # í…Œì´ë¸” ì—†ìŒ ì—ëŸ¬ ì²˜ë¦¬
#         if "relation \"search_vectors\" does not exist" in str(e):
#              raise HTTPException(status_code=404, detail="ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. /index-data ë¡œ ë°ì´í„°ë¥¼ ë¨¼ì € ë„£ì–´ì£¼ì„¸ìš”.")
#         raise HTTPException(status_code=500, detail=str(e))


@app.post("/search")
def search_grouped(request: SearchRequest):
    logger.info(f"ğŸ” ê³ ë„í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìš”ì²­: {request.query}")

    if model is None:
            raise HTTPException(status_code=500, detail="ëª¨ë¸ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤.")

    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # 1. ì¿¼ë¦¬ ë²¡í„° ë³€í™˜ ë° íŒ¨í„´ ìƒì„±
        query_vector = model.encode(request.query).tolist()
        text_pattern = f"%{request.query}%"
        
        # 2. í†µí•© í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ì‹¤í–‰
        # - places, shortforms, local_columns í…Œì´ë¸” ì‹¤ì‹œê°„ ì¡°íšŒ ì¶”ê°€
        
        query_sql = """
        WITH ai_results AS (
            -- [1] ê²€ìƒ‰ ì—”ì§„ ì¸ë±ìŠ¤ í…Œì´ë¸” ì¡°íšŒ
            SELECT target_id, category, content, 
                   (embedding <=> %s::vector) as distance,
                   CASE WHEN content ILIKE %s THEN 0 ELSE 1 END as match_priority
            FROM search_vectors
        ),
        direct_places_results AS (
            -- [2] ì¥ì†Œ í…Œì´ë¸” ì‹¤ì‹œê°„ ì¡°íšŒ
            SELECT id as target_id, 'place' as category, name || ' ' || address as content,
                   0.45 as distance,
                   0 as match_priority
            FROM places
            WHERE (name ILIKE %s OR address ILIKE %s)
            AND id NOT IN (SELECT target_id FROM search_vectors WHERE category = 'place')
        ),
        direct_shorts_results AS (
            -- [3] ìˆì¸  í…Œì´ë¸” ì‹¤ì‹œê°„ ì¡°íšŒ
            SELECT id as target_id, 'shortform' as category, title || ' ' || COALESCE(content, '') as content,
                   0.45 as distance,
                   0 as match_priority
            FROM shortforms
            WHERE (title ILIKE %s OR content ILIKE %s)
            AND id NOT IN (SELECT target_id FROM search_vectors WHERE category = 'shortform')
        ),
        direct_columns_results AS (
            -- [4] â˜… ì¹¼ëŸ¼ í…Œì´ë¸” ì‹¤ì‹œê°„ ì¡°íšŒ ì¶”ê°€ (NEW)
            SELECT id as target_id, 'localcolumn' as category, title || ' ' || SUBSTRING(content, 1, 300) as content,
                   0.45 as distance,
                   0 as match_priority
            FROM local_columns
            WHERE (title ILIKE %s OR content ILIKE %s)
            AND id NOT IN (SELECT target_id FROM search_vectors WHERE category = 'localcolumn')
        ),
        combined AS (
            SELECT * FROM ai_results
            UNION ALL
            SELECT * FROM direct_places_results
            UNION ALL
            SELECT * FROM direct_shorts_results
            UNION ALL
            SELECT * FROM direct_columns_results
        ),
        ranked AS (
            SELECT *,
                   ROW_NUMBER() OVER(
                       PARTITION BY category 
                       ORDER BY match_priority ASC, distance ASC
                   ) as group_rank
            FROM combined
            WHERE distance < 0.5 OR match_priority = 0
        )
        SELECT target_id, category, content, distance, match_priority
        FROM ranked
        WHERE group_rank <= 15
        ORDER BY match_priority ASC, distance ASC;
        """
        
        # íŒŒë¼ë¯¸í„° ë§¤í•‘: AI(2) + Place(2) + Short(2) + Column(2) = ì´ 8ê°œ
        cur.execute(query_sql, (
            query_vector, text_pattern, 
            text_pattern, text_pattern, 
            text_pattern, text_pattern,
            text_pattern, text_pattern 
        ))
        
        rows = cur.fetchall()
        conn.close()
        
        # 3. ê²°ê³¼ ê·¸ë£¹í™”
        grouped_results = {
            "places": [],
            "reviews": [],
            "plans": [],
            "shorts": [],
            "columns": [],  # â˜… ì¹¼ëŸ¼ ì„¹ì…˜ ì¶”ê°€
            "others": []
        }
        
        place_ids = []
        short_ids = []
        column_ids = []
        plan_ids = []
        review_ids = []

        for r in rows:
            item = {
                "id": r[0],
                "content": r[2],
                "distance": float(r[3]),
                "is_keyword_match": True if r[4] == 0 else False
            }

            cat = r[1]
            if cat == "place":
                grouped_results["places"].append(item)
                place_ids.append(item["id"])
            elif cat == "review":
                grouped_results["reviews"].append(item)
                review_ids.append(item["id"])
            elif cat == "plan":
                grouped_results["plans"].append(item)
                plan_ids.append(item["id"])
            elif cat == "shortform":
                grouped_results["shorts"].append(item)
                short_ids.append(item["id"])
            elif cat == "localcolumn": # â˜… ì¹¼ëŸ¼ ë¶„ë¥˜ ì¶”ê°€
                grouped_results["columns"].append(item)
                column_ids.append(item["id"])
            else:
                grouped_results["others"].append(item)
        
        # -----------------------------------------------------
        # 4. ì¶”ê°€ ì •ë³´ ì¡°íšŒ (ì¸ë„¤ì¼, ì œëª© ë“±)
        # -----------------------------------------------------
        
        # [A] Place ì¶”ê°€ ì •ë³´
        if place_ids:
            try:
                conn_places = get_db_connection()
                cur_places = conn_places.cursor()

                place_query = "SELECT id, thumbnail_urls, average_rating, review_count, name, address, source_lang FROM places WHERE id IN %s"
                cur_places.execute(place_query, (tuple(place_ids),))
                place_rows = cur_places.fetchall()

                # ë¦¬ë·° ì´ë¯¸ì§€
                review_query = """
                    SELECT DISTINCT ON (place_id) place_id, image_url
                    FROM place_reviews
                    WHERE place_id IN %s AND image_url IS NOT NULL AND image_url != ''
                    ORDER BY place_id, created_at DESC
                """
                cur_places.execute(review_query, (tuple(place_ids),))
                review_rows = cur_places.fetchall()
                review_map = {row[0]: row[1] for row in review_rows}

                place_map = {}
                for pid, urls, rating, count, name, address, src_lang in place_rows:
                    thumb = None
                    if pid in review_map:
                        thumb = review_map[pid]
                    elif urls and isinstance(urls, list) and len(urls) > 0:
                        thumb = urls[0]

                    place_map[pid] = {
                        "thumbnail_url": thumb,
                        "average_rating": float(rating) if rating else 0.0,
                        "review_count": count if count else 0,
                        "name": name,
                        "address": address,
                        "source_lang": src_lang or "kor_Hang"
                    }

                for item in grouped_results["places"]:
                    info = place_map.get(item["id"], {})
                    item["thumbnail_url"] = info.get("thumbnail_url")
                    item["average_rating"] = info.get("average_rating", 0.0)
                    item["review_count"] = info.get("review_count", 0)
                    item["name"] = info.get("name")
                    item["address"] = info.get("address")
                    item["source_lang"] = info.get("source_lang", "kor_Hang")

                cur_places.close()
                conn_places.close()
            except Exception as e:
                logger.error(f"Place detail error: {e}")

        # [B] Shortform ì¶”ê°€ ì •ë³´
        if short_ids:
            try:
                conn_shorts = get_db_connection()
                cur_shorts = conn_shorts.cursor()

                short_query = "SELECT id, thumbnail_url, title, content, source_lang FROM shortforms WHERE id IN %s"
                cur_shorts.execute(short_query, (tuple(short_ids),))
                short_rows = cur_shorts.fetchall()

                short_map = {}
                for sid, thumb, title, content, src_lang in short_rows:
                    short_map[sid] = {
                        "thumbnail_url": thumb,
                        "title": title,
                        "content": content,
                        "source_lang": src_lang or "kor_Hang"
                    }

                for item in grouped_results["shorts"]:
                    info = short_map.get(item["id"], {})
                    item["thumbnail_url"] = info.get("thumbnail_url")
                    item["title"] = info.get("title")
                    item["content"] = info.get("content")
                    item["source_lang"] = info.get("source_lang", "kor_Hang")

                cur_shorts.close()
                conn_shorts.close()
            except Exception as e:
                logger.error(f"Shortform detail error: {e}")

        # [C] â˜… LocalColumn ì¶”ê°€ ì •ë³´ (NEW)
        if column_ids:
            try:
                conn_cols = get_db_connection()
                cur_cols = conn_cols.cursor()
                
                # ì¹¼ëŸ¼ì€ thumbnail_urlê³¼ titleì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                col_query = "SELECT id, thumbnail_url, title FROM local_columns WHERE id IN %s"
                cur_cols.execute(col_query, (tuple(column_ids),))
                col_rows = cur_cols.fetchall()
                
                col_map = {}
                for cid, thumb, title in col_rows:
                    col_map[cid] = {"thumbnail_url": thumb, "title": title}
                
                for item in grouped_results["columns"]:
                    info = col_map.get(item["id"], {})
                    item["thumbnail_url"] = info.get("thumbnail_url")
                    item["title"] = info.get("title")
                    
                cur_cols.close()
                conn_cols.close()
            except Exception as e:
                logger.error(f"Column detail error: {e}")

        # [D] Plan ì¶”ê°€ ì •ë³´
        if plan_ids:
            try:
                conn_plans = get_db_connection()
                cur_plans = conn_plans.cursor()

                plan_query = "SELECT id, title, description FROM travel_plans WHERE id IN %s"
                cur_plans.execute(plan_query, (tuple(plan_ids),))
                plan_rows = cur_plans.fetchall()

                plan_map = {}
                for pid, title, description in plan_rows:
                    plan_map[pid] = {
                        "title": title,
                        "description": description,
                        "source_lang": "kor_Hang"  # PlansëŠ” source_lang í•„ë“œê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’
                    }

                for item in grouped_results["plans"]:
                    info = plan_map.get(item["id"], {})
                    item["title"] = info.get("title")
                    item["description"] = info.get("description")
                    item["source_lang"] = info.get("source_lang", "kor_Hang")

                cur_plans.close()
                conn_plans.close()
            except Exception as e:
                logger.error(f"Plan detail error: {e}")

        # [E] Review ì¶”ê°€ ì •ë³´
        if review_ids:
            try:
                conn_reviews = get_db_connection()
                cur_reviews = conn_reviews.cursor()

                review_query = "SELECT id, content, source_lang, rating FROM place_reviews WHERE id IN %s"
                cur_reviews.execute(review_query, (tuple(review_ids),))
                review_rows = cur_reviews.fetchall()

                review_map = {}
                for rid, content, src_lang, rating in review_rows:
                    review_map[rid] = {
                        "content": content,
                        "source_lang": src_lang or "kor_Hang",
                        "rating": rating
                    }

                for item in grouped_results["reviews"]:
                    info = review_map.get(item["id"], {})
                    if info.get("content"):
                        item["content"] = info.get("content")
                    item["source_lang"] = info.get("source_lang", "kor_Hang")
                    item["rating"] = info.get("rating", 5)

                cur_reviews.close()
                conn_reviews.close()
            except Exception as e:
                logger.error(f"Review detail error: {e}")

        # -----------------------------------------------------
        # 5. ë²ˆì—­ ì²˜ë¦¬ (lang íŒŒë¼ë¯¸í„°ê°€ ìˆì„ ë•Œë§Œ)
        # -----------------------------------------------------
        if request.lang:
            try:
                conn_trans = get_db_connection()

                # Places ë²ˆì—­
                if grouped_results["places"]:
                    translate_items(
                        grouped_results["places"],
                        request.lang,
                        "place",
                        ["name", "address"],
                        conn_trans
                    )

                # Shorts ë²ˆì—­
                if grouped_results["shorts"]:
                    translate_items(
                        grouped_results["shorts"],
                        request.lang,
                        "shortform",
                        ["title", "content"],
                        conn_trans
                    )

                # Plans ë²ˆì—­
                if grouped_results["plans"]:
                    translate_items(
                        grouped_results["plans"],
                        request.lang,
                        "travel_plan",
                        ["title", "description"],
                        conn_trans
                    )

                # Reviews ë²ˆì—­
                if grouped_results["reviews"]:
                    translate_items(
                        grouped_results["reviews"],
                        request.lang,
                        "place_review",
                        ["content"],
                        conn_trans
                    )

                conn_trans.close()
            except Exception as e:
                logger.error(f"Translation error: {e}")

        return grouped_results
        
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/delete-data")
def delete_data(request: DeleteRequest):
    conn = None
    try:
        # â˜… ì•„ê¹Œ ë§Œë“  íŒŒì¼ì—ì„œ DB ì—°ê²°ì„ ìƒˆë¡œ ë°›ì•„ì˜µë‹ˆë‹¤ (ë…ë¦½ ì‹¤í–‰)
        conn = get_db_connection()
        cur = conn.cursor()
        
        # ì‚­ì œ ì‹¤í–‰
        cur.execute(
            "DELETE FROM search_vectors WHERE target_id = %s AND category = %s",
            (request.id, request.category)
        )
        conn.commit()
        
        deleted_count = cur.rowcount
        print(f"ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ [{request.category}] ID: {request.id} (ê±´ìˆ˜: {deleted_count})")
        
        return {
            "status": "deleted", 
            "count": deleted_count, 
            "id": request.id, 
            "category": request.category
        }

    except Exception as e:
        if conn:
            conn.rollback()
        print(f"âŒ ì‚­ì œ ì—ëŸ¬: {e}")
        return {"status": "error", "message": str(e)}
        
    finally:
        # ì“´ ìì› ë°˜ë‚© (ê¹”ë”)
        if conn:
            cur.close()
            conn.close()
