import logging
import os
from fastapi import FastAPI, HTTPException
# from translation.router import router as translation_router  # AI ë²ˆì—­ ë¼ìš°í„° (Moved)
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Dict, Any
from pydantic import BaseModel
from database import get_db_connection
from prometheus_fastapi_instrumentator import Instrumentator

# ì‚­ì œ ìš”ì²­ ë°ì´í„° ëª¨ë¸
class DeleteRequest(BaseModel):
    id: int      # ì¥ê³ ì—ì„œ ë³´ë‚´ì¤€ ì›ë³¸ ID (Place ID)
    category: str


from dotenv import load_dotenv
load_dotenv()


# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
try:
    from sentence_transformers import SentenceTransformer
    import psycopg2
    from pgvector.psycopg2 import register_vector
except ImportError as e:
    print(f"CRITICAL ERROR: í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤! -> {e}")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()
Instrumentator().instrument(app).expose(app)

# ---------------------------------------------------------
# CORS ì„¤ì • (ëª¨ë“  ë„ë©”ì¸ í—ˆìš© - ê°œë°œìš©)
# ---------------------------------------------------------
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì£¼ì†Œ í—ˆìš© (OPTIONS 400 ì—ëŸ¬ í•´ê²°)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ëª¨ë¸ ì „ì—­ ë³€ìˆ˜
model = None

# ---------------------------------------------------------
# â˜… DB ì„¤ì • 
# ---------------------------------------------------------
DB_HOST = os.getenv("DB_HOST", "db")
DB_NAME = os.getenv("DB_NAME", "korea_travel_db")
DB_USER = os.getenv("DB_USER", "myuser")
DB_PASS = os.getenv("DB_PASSWORD", "mypassword")

def init_db():
    """ì„œë²„ ì‹œì‘ ì‹œ í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # í…Œì´ë¸” ìƒì„± (IF NOT EXISTS)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS search_vectors (
                uid SERIAL PRIMARY KEY,
                target_id INT,
                category VARCHAR(50),
                content TEXT,
                embedding vector(384) 
            );
        """)
        # ì¸ë±ìŠ¤ ìƒì„± (ì†ë„ í–¥ìƒì„ ìœ„í•´ ê¶Œì¥ - ivfflat ë°©ì‹ ì˜ˆì‹œ)
        # ë°ì´í„°ê°€ ì ì„ ë• ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¼ë‹¨ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜, ë°ì´í„° ìŒ“ì¸ í›„ ìƒì„±
        # cur.execute("CREATE INDEX ON search_vectors USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);")
        
        conn.commit()
        cur.close()
        conn.close()
        logger.info("âœ… DB í…Œì´ë¸” ì´ˆê¸°í™” ì™„ë£Œ (search_vectors)")
    except Exception as e:
        logger.error(f"âŒ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

@app.on_event("startup")
async def startup_event():
    global model
    
    # 1. DB í…Œì´ë¸” ë¨¼ì € ìƒì„± (ìˆœì„œ ì¤‘ìš”)
    init_db()
    
    # 2. ëª¨ë¸ ë¡œë”©
    logger.info("ğŸš€ AI ëª¨ë¸ ë¡œë”© ì‹œì‘...")
    try:
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        logger.info("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")

def get_db_connection():
    try:
        conn = psycopg2.connect(host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASS)
        cur = conn.cursor()
        cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
        conn.commit()
        register_vector(conn)
        return conn
    except Exception as e:
        logger.error(f"DB ì—°ê²° ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail=f"DB Connection Error: {str(e)}")




# ---------------------------------------------------------
# AI ë²ˆì—­ ë¼ìš°í„° ë“±ë¡ (Hugging Face Inference API)
# ---------------------------------------------------------
# ---------------------------------------------------------
# AI ë²ˆì—­ ë¼ìš°í„° ë“±ë¡ (Removed: Moved to fastapi_ai_translation)
# ---------------------------------------------------------
# app.include_router(translation_router, prefix="/api/ai", tags=["translation"])






# ---------------------------------------------------------
# 1. í†µí•© ë°ì´í„° ë“±ë¡ API (Index Data)
# ---------------------------------------------------------
class IndexRequest(BaseModel):
    id: int          # ì›ë³¸ ID (ì¥ì†ŒID, ì¹¼ëŸ¼ID, ë¦¬ë·°ID ë“±)
    category: str    # ë¶„ë¥˜ ('place', 'column', 'review', 'plan' ë“±)
    content: str     # ê²€ìƒ‰ë  í…ìŠ¤íŠ¸ ë‚´ìš©

@app.post("/index-data")
def index_data(request: IndexRequest):
    if model is None:
        raise HTTPException(status_code=500, detail="Model is loading...")

    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # â˜… í…Œì´ë¸” êµ¬ì¡° ë³€ê²½: category ì»¬ëŸ¼ ì¶”ê°€!
        cur.execute("""
            CREATE TABLE IF NOT EXISTS search_vectors (
                uid SERIAL PRIMARY KEY,
                target_id INT,           -- ì›ë³¸ ë°ì´í„°ì˜ ID
                category VARCHAR(50),    -- ë°ì´í„° ì¢…ë¥˜ (place, review ë“±)
                content TEXT,
                embedding vector(384) 
            );
        """)
        
        # â˜… Unique Index ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€ìš©)
        cur.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_target_category ON search_vectors (target_id, category);")
        
        # í…ìŠ¤íŠ¸ -> ë²¡í„° ë³€í™˜
        embedding = model.encode(request.content).tolist()
        
        # ë°ì´í„° ì €ì¥ (UPSERT: ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…)
        query = """
            INSERT INTO search_vectors (target_id, category, content, embedding) 
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (target_id, category) 
            DO UPDATE SET content = EXCLUDED.content, embedding = EXCLUDED.embedding;
        """
        cur.execute(query, (request.id, request.category, request.content, embedding))
        conn.commit()
        conn.close()
        
        logger.info(f"ë°ì´í„° ë“±ë¡ ì„±ê³µ [{request.category}]: {request.content}")
        return {"status": "success", "message": f"Indexed ({request.category}): {request.content}"}
        
    except Exception as e:
        logger.error(f"ë“±ë¡ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ---------------------------------------------------------
# 2. í†µí•© ê²€ìƒ‰ API (ë¶„ë¥˜ëœ ê²°ê³¼ ë°˜í™˜)
# ---------------------------------------------------------
class SearchRequest(BaseModel):
    query: str

# @app.post("/search")
# def search_grouped(request: SearchRequest):
#     logger.info(f"ğŸ” ë¶„ë¥˜ ê²€ìƒ‰ ìš”ì²­: {request.query}")

#     if model is None:
#         raise HTTPException(status_code=500, detail="Model is loading...")

#     try:
#         conn = get_db_connection()
#         cur = conn.cursor()
        
#         # 1. ì¿¼ë¦¬ ë²¡í„° ë³€í™˜
#         query_vector = model.encode(request.query).tolist()
#         text_pattern = f"%{request.query}%"

#         # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ í¬í•¨ ì‹œ ìš°ì„ ìˆœìœ„)
#         # category ì»¬ëŸ¼ë„ ê°™ì´ ì¡°íšŒí•©ë‹ˆë‹¤.
#         cur.execute("""
#             SELECT target_id, category, content, (embedding <=> %s::vector) as distance,
#                    CASE WHEN content ILIKE %s THEN 0 ELSE 1 END as match_priority
#             FROM search_vectors
#             ORDER BY match_priority ASC, distance ASC
#             LIMIT 30;  -- ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ê°€ ì„ì—¬ ë‚˜ì˜¤ë¯€ë¡œ ë„‰ë„‰í•˜ê²Œ ì¡°íšŒ
#         """, (query_vector, text_pattern))
        
#         rows = cur.fetchall()
#         conn.close()
        
#         # 3. â˜… íŒŒì´ì¬ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë°•ìŠ¤ ë‹´ê¸° (Grouping)
#         grouped_results = {
#             "places": [],
#             "reviews": [],
#             "plans": [],
#             "others": []
#         }
        
#         for r in rows:
#             item = {
#                 "id": r[0],
#                 "content": r[2],
#                 "distance": float(r[3]),
#                 "is_keyword_match": True if r[4] == 0 else False
#             }
            
#             # ê¼¬ë¦¬í‘œ(category) í™•ì¸ í›„ ë¶„ë¥˜
#             cat = r[1] 
#             if cat == "place":
#                 grouped_results["places"].append(item)
#             elif cat == "review":
#                 grouped_results["reviews"].append(item)
#             elif cat == "plan":
#                 grouped_results["plans"].append(item)
#             else:
#                 grouped_results["others"].append(item)
        
#         return grouped_results
        
#     except Exception as e:
#         logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
#         # í…Œì´ë¸” ì—†ìŒ ì—ëŸ¬ ì²˜ë¦¬
#         if "relation \"search_vectors\" does not exist" in str(e):
#              raise HTTPException(status_code=404, detail="ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. /index-data ë¡œ ë°ì´í„°ë¥¼ ë¨¼ì € ë„£ì–´ì£¼ì„¸ìš”.")
#         raise HTTPException(status_code=500, detail=str(e))


@app.post("/search")
def search_grouped(request: SearchRequest):
    logger.info(f"ğŸ” ê³ ë„í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìš”ì²­: {request.query}")

    if model is None:
        raise HTTPException(status_code=500, detail="Model is loading...")

    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # 1. ì¿¼ë¦¬ ë²¡í„° ë³€í™˜ ë° íŒ¨í„´ ìƒì„±
        query_vector = model.encode(request.query).tolist()
        text_pattern = f"%{request.query}%"
        
        # 2. í†µí•© í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ì‹¤í–‰
        # - search_vectors: AI ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰
        # - places: ì¸ë±ì‹±ë˜ì§€ ì•Šì€ ìµœì‹  ì¥ì†Œ ë°ì´í„° í‚¤ì›Œë“œ ê²€ìƒ‰ (Fallback)
        # - ROW_NUMBER: ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ ë³´ì¥
        
        query_sql = """
        WITH ai_results AS (
            -- [1] ê²€ìƒ‰ ì—”ì§„ ì¸ë±ìŠ¤ í…Œì´ë¸” ì¡°íšŒ
            SELECT target_id, category, content, 
                   (embedding <=> %s::vector) as distance,
                   CASE WHEN content ILIKE %s THEN 0 ELSE 1 END as match_priority
            FROM search_vectors
        ),
        direct_db_results AS (
            -- [2] ì›ë³¸ places í…Œì´ë¸” ì‹¤ì‹œê°„ ì¡°íšŒ (ì¸ë±ì‹± ëˆ„ë½ ë°©ì§€)
            -- SQLAlchemyë¡œ ì§ì ‘ ì¶”ê°€ëœ í•­ëª© ë“±ì„ ê²€ìƒ‰ ëŒ€ìƒì— ì¦‰ì‹œ í¬í•¨
            SELECT id as target_id, 'place' as category, name || ' ' || address as content,
                   0.45 as distance, -- í‚¤ì›Œë“œ ë§¤ì¹­ì€ ì¤‘ê°„ ì •ë„ì˜ ê±°ë¦¬ê°’ ë¶€ì—¬
                   0 as match_priority
            FROM places
            WHERE (name ILIKE %s OR address ILIKE %s)
            -- ì¸ë±ìŠ¤ì— ì´ë¯¸ ìˆëŠ” ì¥ì†ŒëŠ” ì¤‘ë³µ ì œì™¸
            AND id NOT IN (SELECT target_id FROM search_vectors WHERE category = 'place')
        ),
        combined AS (
            SELECT * FROM ai_results
            UNION ALL
            SELECT * FROM direct_db_results
        ),
        ranked AS (
            SELECT *,
                   ROW_NUMBER() OVER(
                       PARTITION BY category 
                       ORDER BY match_priority ASC, distance ASC
                   ) as group_rank
            FROM combined
            -- â˜… ì¡°ê±´: ê±°ë¦¬ 0.5 ë¯¸ë§Œ(ìœ ì‚¬í•¨) ì´ê±°ë‚˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°ë§Œ ë…¸ì¶œ
            WHERE distance < 0.5 OR match_priority = 0
        )
        SELECT target_id, category, content, distance, match_priority
        FROM ranked
        WHERE group_rank <= 15  -- â˜… ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ 15ê°œì”© ê²°ê³¼ ë³´ì¥
        ORDER BY match_priority ASC, distance ASC;
        """
        
        # íŒŒë¼ë¯¸í„°: query_vector, text_pattern, text_pattern, text_pattern
        cur.execute(query_sql, (query_vector, text_pattern, text_pattern, text_pattern))
        
        rows = cur.fetchall()
        conn.close()
        
        # 3. ê²°ê³¼ ê·¸ë£¹í™” (í”„ë¡ íŠ¸ì—”ë“œ ë°˜í™˜ í¬ë§·)
        grouped_results = {
            "places": [],
            "reviews": [],
            "plans": [],
            "shorts": [],
            "others": []
        }
        
        place_ids = []
        short_ids = []
        
        for r in rows:
            item = {
                "id": r[0],
                "content": r[2],
                "distance": float(r[3]),
                "is_keyword_match": True if r[4] == 0 else False
            }
            
            cat = r[1]
            if cat == "place":
                grouped_results["places"].append(item)
                place_ids.append(item["id"])
            elif cat == "review":
                grouped_results["reviews"].append(item)
            elif cat == "plan":
                grouped_results["plans"].append(item)
            elif cat == "shortform":
                grouped_results["shorts"].append(item)
                short_ids.append(item["id"])
            else:
                grouped_results["others"].append(item)
        
        # 4. ì¶”ê°€ ì •ë³´(ì¸ë„¤ì¼, í‰ì , ë¦¬ë·°ì‚¬ì§„ ë“±) ì¡°íšŒ - Place
        if place_ids:
            try:
                conn_places = get_db_connection()
                cur_places = conn_places.cursor()
                
                # [1] Place ì •ë³´ (í‰ì , ë¦¬ë·°ìˆ˜, ê¸°ë³¸ ì¸ë„¤ì¼)
                place_query_sql = "SELECT id, thumbnail_urls, average_rating, review_count FROM places WHERE id IN %s"
                cur_places.execute(place_query_sql, (tuple(place_ids),))
                place_rows = cur_places.fetchall()
                
                # [2] ë¦¬ë·° ì‚¬ì§„ (ê° ì¥ì†Œë³„ ìµœì‹  1ì¥)
                # DISTINCT ON (place_id)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì¥ì†Œë³„ ê°€ì¥ ìµœê·¼ ë¦¬ë·° ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜´
                review_query_sql = """
                    SELECT DISTINCT ON (place_id) place_id, image_url 
                    FROM place_reviews 
                    WHERE place_id IN %s AND image_url IS NOT NULL AND image_url != ''
                    ORDER BY place_id, created_at DESC
                """
                cur_places.execute(review_query_sql, (tuple(place_ids),))
                review_rows = cur_places.fetchall()
                review_map = {row[0]: row[1] for row in review_rows}
                
                place_map = {}
                for pid, urls, rating, count in place_rows:
                    thumb = None
                    
                    # ìš°ì„ ìˆœìœ„: ë¦¬ë·° ì‚¬ì§„ > ì¥ì†Œ ëŒ€í‘œ ì‚¬ì§„
                    if pid in review_map:
                        thumb = review_map[pid]
                    elif urls and isinstance(urls, list) and len(urls) > 0:
                        thumb = urls[0]
                    
                    place_map[pid] = {
                        "thumbnail_url": thumb,
                        "average_rating": float(rating) if rating else 0.0,
                        "review_count": count if count else 0
                    }
                
                for item in grouped_results["places"]:
                    info = place_map.get(item["id"], {})
                    item["thumbnail_url"] = info.get("thumbnail_url")
                    item["average_rating"] = info.get("average_rating", 0.0)
                    item["review_count"] = info.get("review_count", 0)
                
                cur_places.close()
                conn_places.close()
            except Exception as e:
                logger.error(f"Place ì¶”ê°€ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # 5. ì¶”ê°€ ì •ë³´(ì¸ë„¤ì¼, ì œëª© ë“±) ì¡°íšŒ - Shortform
        if short_ids:
            try:
                conn_shorts = get_db_connection()
                cur_shorts = conn_shorts.cursor()
                # shortforms í…Œì´ë¸”ì—ì„œ thumbnail_url, title ê°€ì ¸ì˜¤ê¸°
                short_query_sql = "SELECT id, thumbnail_url, title FROM shortforms WHERE id IN %s"
                cur_shorts.execute(short_query_sql, (tuple(short_ids),))
                short_rows = cur_shorts.fetchall()
                
                short_map = {}
                for sid, thumb, title in short_rows:
                    short_map[sid] = {
                        "thumbnail_url": thumb,
                        "title": title
                    }
                
                for item in grouped_results["shorts"]:
                    info = short_map.get(item["id"], {})
                    item["thumbnail_url"] = info.get("thumbnail_url")
                    item["title"] = info.get("title")
                    
                cur_shorts.close()
                conn_shorts.close()
            except Exception as e:
                logger.error(f"Shortform ì¶”ê°€ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        return grouped_results
        
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/delete-data")
def delete_data(request: DeleteRequest):
    conn = None
    try:
        # â˜… ì•„ê¹Œ ë§Œë“  íŒŒì¼ì—ì„œ DB ì—°ê²°ì„ ìƒˆë¡œ ë°›ì•„ì˜µë‹ˆë‹¤ (ë…ë¦½ ì‹¤í–‰)
        conn = get_db_connection()
        cur = conn.cursor()
        
        # ì‚­ì œ ì‹¤í–‰
        cur.execute(
            "DELETE FROM search_vectors WHERE target_id = %s AND category = %s",
            (request.id, request.category)
        )
        conn.commit()
        
        deleted_count = cur.rowcount
        print(f"ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ [{request.category}] ID: {request.id} (ê±´ìˆ˜: {deleted_count})")
        
        return {
            "status": "deleted", 
            "count": deleted_count, 
            "id": request.id, 
            "category": request.category
        }

    except Exception as e:
        if conn:
            conn.rollback()
        print(f"âŒ ì‚­ì œ ì—ëŸ¬: {e}")
        return {"status": "error", "message": str(e)}
        
    finally:
        # ì“´ ìì› ë°˜ë‚© (ê¹”ë”)
        if conn:
            cur.close()
            conn.close()